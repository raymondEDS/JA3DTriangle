{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clip_similiarty.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DEWsUV2k4I_qNj86neE37Qq9UCGgMhca",
      "authorship_tag": "ABX9TyOJLBNVEo1w8YQzr56GYcSi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raymondEDS/iFind_tech_team/blob/clip_matching/Clip_similiarty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is meant to match clips with the longer raw footage. The bases of the code is from: https://aws.amazon.com/blogs/media/metfc-automatically-compare-two-videos-to-find-common-content/"
      ],
      "metadata": {
        "id": "D_JYJ8blZJRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JbBEoUdcsDJ",
        "outputId": "a3b797ff-bb0c-4998-e8ab-538a1c8d0e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from skimage import io\n",
        "from PIL import Image \n",
        "import matplotlib.pylab as plt"
      ],
      "metadata": {
        "id": "S9yYVjr-a-Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to mount drive first.\n",
        "\n",
        "The path to the entire raw file is:\n",
        "/content/drive/MyDrive/ifind/Raw Footage/Dyad and Family /UI006/UI006.mp4\n",
        "\n",
        "\n",
        "Path to clip is:\n",
        "/content/drive/MyDrive/ifind/Training Video/1 FIND Unedited Clips/1. Sharing the Focus/UI006USF.mp4\n"
      ],
      "metadata": {
        "id": "cHWe1ZXRd0UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clip_length(path):\n",
        "  cap = cv.VideoCapture(path)\n",
        "  length = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "  print( length )\n",
        "\n",
        "\n",
        "def first_frame_of_clip(clip_obj):\n",
        "  #Grab the first frame of the clip of interest\n",
        "  #return frame\n",
        "\n",
        "\n",
        "def find_match_start(raw_video, first_frame_of_clip):\n",
        "  #TODO\n",
        "  #loop through the raw file until you find the match of the first frame\n",
        "  #use the matching methods in the cell below from the tutorial\n",
        "  #save the timestop or frame number of the matched frame\n",
        "  #add the number of frames from the clip_length method to that frame number this will be the last frame of the clip\n",
        "  #return the first and last frame timestamp"
      ],
      "metadata": {
        "id": "D7drH3IRrnE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"/content/drive/MyDrive/ifind/Training Video/1 FIND Unedited Clips/1. Sharing the Focus/UI006USF.mp4\"\n",
        "\n",
        "clip_length(test)\n",
        "\n",
        "test2 = '/content/drive/MyDrive/ifind/Raw Footage/Dyad and Family /UI006/UI006.mp4'\n",
        "clip_length(test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3rOo-KRtlo0",
        "outputId": "97fa4027-2a8a-438b-dfd0-8a29d216d056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "286\n",
            "27420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#https://docs.opencv.org/4.x/d5/dc4/tutorial_video_input_psnr_ssim.html\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python 2/3 compatibility\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "import sys\n",
        "# [get-psnr]\n",
        "def getPSNR(I1, I2):\n",
        "    s1 = cv.absdiff(I1, I2) #|I1 - I2|\n",
        "    s1 = np.float32(s1)     # cannot make a square on 8 bits\n",
        "    s1 = s1 * s1            # |I1 - I2|^2\n",
        "    sse = s1.sum()          # sum elements per channel\n",
        "    if sse <= 1e-10:        # sum channels\n",
        "        return 0            # for small values return zero\n",
        "    else:\n",
        "        shape = I1.shape\n",
        "        mse = 1.0 * sse / (shape[0] * shape[1] * shape[2])\n",
        "        psnr = 10.0 * np.log10((255 * 255) / mse)\n",
        "        return psnr\n",
        "# [get-psnr]\n",
        "# [get-mssim]\n",
        "def getMSSISM(i1, i2):\n",
        "    C1 = 6.5025\n",
        "    C2 = 58.5225\n",
        "    # INITS\n",
        "    I1 = np.float32(i1) # cannot calculate on one byte large values\n",
        "    I2 = np.float32(i2)\n",
        "    I2_2 = I2 * I2 # I2^2\n",
        "    I1_2 = I1 * I1 # I1^2\n",
        "    I1_I2 = I1 * I2 # I1 * I2\n",
        "    # END INITS\n",
        "    # PRELIMINARY COMPUTING\n",
        "    mu1 = cv.GaussianBlur(I1, (11, 11), 1.5)\n",
        "    mu2 = cv.GaussianBlur(I2, (11, 11), 1.5)\n",
        "    mu1_2 = mu1 * mu1\n",
        "    mu2_2 = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_2 = cv.GaussianBlur(I1_2, (11, 11), 1.5)\n",
        "    sigma1_2 -= mu1_2\n",
        "    sigma2_2 = cv.GaussianBlur(I2_2, (11, 11), 1.5)\n",
        "    sigma2_2 -= mu2_2\n",
        "    sigma12 = cv.GaussianBlur(I1_I2, (11, 11), 1.5)\n",
        "    sigma12 -= mu1_mu2\n",
        "    t1 = 2 * mu1_mu2 + C1\n",
        "    t2 = 2 * sigma12 + C2\n",
        "    t3 = t1 * t2                    # t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))\n",
        "    t1 = mu1_2 + mu2_2 + C1\n",
        "    t2 = sigma1_2 + sigma2_2 + C2\n",
        "    t1 = t1 * t2                    # t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))\n",
        "    ssim_map = cv.divide(t3, t1)    # ssim_map =  t3./t1;\n",
        "    mssim = cv.mean(ssim_map)       # mssim = average of ssim map\n",
        "    return mssim\n",
        "# [get-mssim]\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"-d\", \"--delay\", type=int, default=30, help=\" Time delay\")\n",
        "    parser.add_argument(\"-v\", \"--psnrtriggervalue\", type=int, default=30, help=\"PSNR Trigger Value\")\n",
        "    parser.add_argument(\"-r\", \"--ref\", type=str, default=\"Megamind.avi\", help=\"Path to reference video\")\n",
        "    parser.add_argument(\"-t\", \"--undertest\", type=str, default=\"Megamind_bugy.avi\",\n",
        "                        help=\"Path to the video to be tested\")\n",
        "    args = parser.parse_args()\n",
        "    sourceReference = args.ref\n",
        "    sourceCompareWith = args.undertest\n",
        "    delay = args.delay\n",
        "    psnrTriggerValue = args.psnrtriggervalue\n",
        "    framenum = -1 # Frame counter\n",
        "    captRefrnc = cv.VideoCapture(cv.samples.findFileOrKeep(sourceReference))\n",
        "    captUndTst = cv.VideoCapture(cv.samples.findFileOrKeep(sourceCompareWith))\n",
        "    if not captRefrnc.isOpened():\n",
        "        print(\"Could not open the reference \" + sourceReference)\n",
        "        sys.exit(-1)\n",
        "    if not captUndTst.isOpened():\n",
        "        print(\"Could not open case test \" + sourceCompareWith)\n",
        "        sys.exit(-1)\n",
        "    refS = (int(captRefrnc.get(cv.CAP_PROP_FRAME_WIDTH)), int(captRefrnc.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
        "    uTSi = (int(captUndTst.get(cv.CAP_PROP_FRAME_WIDTH)), int(captUndTst.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
        "    if refS != uTSi:\n",
        "        print(\"Inputs have different size!!! Closing.\")\n",
        "        sys.exit(-1)\n",
        "    WIN_UT = \"Under Test\"\n",
        "    WIN_RF = \"Reference\"\n",
        "    cv.namedWindow(WIN_RF, cv.WINDOW_AUTOSIZE)\n",
        "    cv.namedWindow(WIN_UT, cv.WINDOW_AUTOSIZE)\n",
        "    cv.moveWindow(WIN_RF, 400, 0) #750,  2 (bernat =0)\n",
        "    cv.moveWindow(WIN_UT, refS[0], 0) #1500, 2\n",
        "    print(\"Reference frame resolution: Width={} Height={} of nr#: {}\".format(refS[0], refS[1],\n",
        "                                                                             captRefrnc.get(cv.CAP_PROP_FRAME_COUNT)))\n",
        "    print(\"PSNR trigger value {}\".format(psnrTriggerValue))\n",
        "    while True: # Show the image captured in the window and repeat\n",
        "        _, frameReference = captRefrnc.read()\n",
        "        _, frameUnderTest = captUndTst.read()\n",
        "        if frameReference is None or frameUnderTest is None:\n",
        "            print(\" < < <  Game over!  > > > \")\n",
        "            break\n",
        "        framenum += 1\n",
        "        psnrv = getPSNR(frameReference, frameUnderTest)\n",
        "        print(\"Frame: {}# {}dB\".format(framenum, round(psnrv, 3)), end=\" \")\n",
        "        if (psnrv < psnrTriggerValue and psnrv):\n",
        "            mssimv = getMSSISM(frameReference, frameUnderTest)\n",
        "            print(\"MSSISM: R {}% G {}% B {}%\".format(round(mssimv[2] * 100, 2), round(mssimv[1] * 100, 2),\n",
        "                                                     round(mssimv[0] * 100, 2)), end=\" \")\n",
        "        print()\n",
        "        cv.imshow(WIN_RF, frameReference)\n",
        "        cv.imshow(WIN_UT, frameUnderTest)\n",
        "        k = cv.waitKey(delay)\n",
        "        if k == 27:\n",
        "            break\n",
        "    sys.exit(0)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5X3ZWkyIf1dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4d70bf55-3174-419d-a66c-9f77e4736c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-d DELAY] [-v PSNRTRIGGERVALUE] [-r REF]\n",
            "                             [-t UNDERTEST]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-42e0468d-4841-4d18-aad9-732f160c7689.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}
